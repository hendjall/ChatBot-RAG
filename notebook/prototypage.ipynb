{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6929683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected!\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    port=5432,\n",
    "    dbname=\"rag-chatBot\",\n",
    "    user=\"postgres\",\n",
    "    password=\"hend\"\n",
    ")\n",
    "print(\"Connected!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb6691bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extension pgvector créée\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"CREATE EXTENSION IF NOT EXISTS vector;\")\n",
    "    print(\"Extension pgvector créée\")\n",
    "    conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d41f0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jallo\\OneDrive - Ministere de l'Enseignement Superieur et de la Recherche Scientifique\\Bureau\\ChatBot-RAG\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\jallo\\OneDrive - Ministere de l'Enseignement Superieur et de la Recherche Scientifique\\Bureau\\ChatBot-RAG\\env\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\jallo\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    }
   ],
   "source": [
    "# Charger le modèle de embeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embedding_dim = model.get_sentence_embedding_dimension() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fae773a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table embeddings créée\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "    #si je veux supprimer la table existante\n",
    "    cur.execute(\"DROP TABLE IF EXISTS embeddings;\")\n",
    "    \n",
    "    # Créer la table avec le paramètre embedding_dim\n",
    "    cur.execute(f\"\"\"\n",
    "        CREATE TABLE embeddings (\n",
    "            id SERIAL PRIMARY KEY,\n",
    "            corpus TEXT,\n",
    "            embedding VECTOR({embedding_dim})\n",
    "        );\n",
    "    \"\"\")\n",
    "    \n",
    "    print(\"Table embeddings créée\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71e103c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "def create_conversation_list(file_path: str) -> List[str]:\n",
    "    encodings = ['utf-8', 'latin-1', 'cp1252', 'iso-8859-1']\n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            with open(file_path, \"r\", encoding=encoding) as file:\n",
    "                text = file.read()\n",
    "                if not text.strip():\n",
    "                    print(f\"Aucun contenu valide trouvé dans le fichier: {file_path}\")\n",
    "                    return []\n",
    "\n",
    "                text_list = text.split(\"\\n\")\n",
    "                filtered_list = [chaine.removeprefix(\"     \").strip() \n",
    "                                 for chaine in text_list if chaine.strip() and not chaine.startswith(\"<\")]\n",
    "\n",
    "                if not filtered_list:\n",
    "                    print(f\"Aucune ligne valide trouvée dans le fichier: {file_path}\")\n",
    "                else:\n",
    "                    print(f\"Lignes valides trouvées avec l'encodage {encoding}: {len(filtered_list)}\")\n",
    "\n",
    "                return filtered_list\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de la lecture du fichier {file_path} avec l'encodage {encoding}: {e}\")\n",
    "            return []\n",
    "\n",
    "    print(f\"Impossible de lire le fichier {file_path} avec les encodages testés.\")\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40ba9d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour calculer les embeddings avec SentenceTransformer\n",
    "def calculate_embeddings(corpus: str) -> List[float]:\n",
    "    return model.encode([corpus])[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d624d5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_embedding(corpus: str, embedding: List[float], cursor):\n",
    "    cursor.execute(\n",
    "        \"INSERT INTO embeddings (corpus, embedding) VALUES (%s, %s)\",\n",
    "        (corpus, embedding)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ba5f7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour trouver les textes similaires\n",
    "from typing import List, Tuple\n",
    "\n",
    "def similar_corpus(input_corpus: str, top_k: int = 3) -> List[Tuple[int, str, float]]:\n",
    "    input_embedding = calculate_embeddings(input_corpus)\n",
    "\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\"\"\"\n",
    "            SELECT id, corpus, embedding <=> %s AS distance\n",
    "            FROM embeddings\n",
    "            ORDER BY distance\n",
    "            LIMIT %s;\n",
    "        \"\"\", (input_embedding, top_k))\n",
    "        results = cur.fetchall()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "582f4af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [\n",
    "    \"../data/TRANS_TXT/017_00000012.txt\",\n",
    "    \"../data/TRANS_TXT/018_00000013.txt\",\n",
    "    \"../data/TRANS_TXT/019_00000014.txt\",\n",
    "    \"../data/TRANS_TXT/020_00000015.txt\",\n",
    "    \"../data/TRANS_TXT/038_00000027.txt\",\n",
    "    ]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad84a74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lignes valides trouvées avec l'encodage latin-1: 43\n",
      "Lignes valides trouvées avec l'encodage latin-1: 9\n",
      "Lignes valides trouvées avec l'encodage latin-1: 12\n",
      "Lignes valides trouvées avec l'encodage latin-1: 13\n",
      "Lignes valides trouvées avec l'encodage latin-1: 35\n",
      "112 lignes valides chargées depuis tous les fichiers\n",
      "Tous les embeddings ont été insérés dans la base de données\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "# Charger le corpus depuis tous les fichiers\n",
    "corpus_list = []\n",
    "for path in file_paths:\n",
    "    if os.path.exists(path):\n",
    "        lines = create_conversation_list(path)\n",
    "        corpus_list.extend(lines)\n",
    "    else:\n",
    "        print(f\"Fichier introuvable et ignoré : {path}\")\n",
    "\n",
    "if not corpus_list:\n",
    "    print(\"Aucune ligne valide n'a été chargée.\")\n",
    "else:\n",
    "    print(f\"{len(corpus_list)} lignes valides chargées depuis tous les fichiers\")\n",
    "\n",
    "# Insérer les embeddings dans la base de données\n",
    "with conn.cursor() as cur:\n",
    "    for i, corpus in enumerate(corpus_list):\n",
    "        try:\n",
    "            embedding = calculate_embeddings(corpus)\n",
    "            save_embedding(corpus, embedding, cur)\n",
    "            if i % 10 == 0:  # délai toutes les 10 lignes pour éviter surcharge\n",
    "                time.sleep(1)\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de la génération de l'embedding pour la ligne {i}: {e}\")\n",
    "    conn.commit()\n",
    "\n",
    "print(\"Tous les embeddings ont été insérés dans la base de données\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65830ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 1\n",
      "Corpus: h: U B S bonjour\n",
      "Embedding (longueur 4717): [-0.055600 ...\n",
      "---\n",
      "ID: 2\n",
      "Corpus: c: oui bonjour e j'appelle je sais pas si j'appelle au bon endroit e\n",
      "Embedding (longueur 4703): [-0.051114 ...\n",
      "---\n",
      "ID: 3\n",
      "Corpus: h: je vous écoute\n",
      "Embedding (longueur 4709): [-0.031032 ...\n",
      "---\n",
      "ID: 4\n",
      "Corpus: c: c'est pour\n",
      "Embedding (longueur 4731): [-0.057875 ...\n",
      "---\n",
      "ID: 10\n",
      "Corpus: h: oui\n",
      "Embedding (longueur 4706): [-0.086280 ...\n",
      "---\n",
      "ID: 5\n",
      "Corpus: c: e c'est pour savoir si la fac pendant l'été e a des professeurs ou des des gens qui font des stages de de perfectionnement en anglais et en espagnol\n",
      "Embedding (longueur 4700): [-0.031055 ...\n",
      "---\n",
      "ID: 6\n",
      "Corpus: h: e ce serait pour vous vous souhaiteriez\n",
      "Embedding (longueur 4704): [-0.044720 ...\n",
      "---\n",
      "ID: 7\n",
      "Corpus: h: non\n",
      "Embedding (longueur 4697): [0.0024821 ...\n",
      "---\n",
      "ID: 8\n",
      "Corpus: c: non non c'est pas pour moi\n",
      "Embedding (longueur 4699): [-0.031244 ...\n",
      "---\n",
      "ID: 9\n",
      "Corpus: c: ce serait pour ma fille\n",
      "Embedding (longueur 4704): [-0.052667 ...\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SELECT id, corpus, embedding FROM embeddings LIMIT 10;\")\n",
    "    rows = cur.fetchall()\n",
    "    for row in rows:\n",
    "        print(f\"ID: {row[0]}\")\n",
    "        print(f\"Corpus: {row[1]}\")\n",
    "        print(f\"Embedding (longueur {len(row[2])}): {row[2][:10]} ...\")  # affiche les 10 premières valeurs\n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33cb00d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transaction PostgreSQL réinitialisée\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "print(\"Transaction PostgreSQL réinitialisée\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f26f7b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cette version transforme la liste de floats en string pour que pgvector puisse comparer.\n",
    "#Fonction de similarité utilisant pgvector sous forme de string\n",
    "\n",
    "def similar_corpus(input_corpus: str, top_k: int = 3):\n",
    "    # Embedding Python → liste de floats\n",
    "    input_embedding = calculate_embeddings(input_corpus)\n",
    "\n",
    "    # Transformer en format pgvector \"[0.1, 0.2, ...]\"\n",
    "    vector_str = \"[\" + \",\".join(map(str, input_embedding)) + \"]\"\n",
    "\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\"\"\"\n",
    "            SELECT id, corpus, embedding <=> %s AS distance\n",
    "            FROM embeddings\n",
    "            ORDER BY distance\n",
    "            LIMIT %s;\n",
    "        \"\"\", (vector_str, top_k))\n",
    "\n",
    "        return cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c313b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 99\n",
      "Corpus: c: e j'aimerais savoir e j'ai une réunion ce soir e\n",
      "Distance: 0.16857526208684592\n",
      "---\n",
      "ID: 107\n",
      "Corpus: h: oui c'est rue de la Loi la réunion\n",
      "Distance: 0.35858507650075977\n",
      "---\n",
      "ID: 84\n",
      "Corpus: h: ce soir il doit y avoir une réunion sur le D A E U qui doit se faire à l'I U(P) e rue de la Loi\n",
      "Distance: 0.38081274146957633\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "test_text = \"Bonjour, j’aimerais savoir où se trouve la réunion de ce soir.\"\n",
    "results = similar_corpus(test_text, top_k=3)\n",
    "\n",
    "for r in results:\n",
    "    print(f\"ID: {r[0]}\")\n",
    "    print(f\"Corpus: {r[1]}\")\n",
    "    print(f\"Distance: {r[2]}\")\n",
    "    print(\"---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
